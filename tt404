#!/usr/bin/python
from __future__ import with_statement

from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
from  lxml import etree
import urllib, urllib2
import re
from itertools import ifilter
import json
import base64
from conf import libBlacklist, pluginBlacklist, noManage, noBrowse, plexOnlineOnly, viewerAge
import datetime
import contentRatings
import pickle
import urlparse
import threading
import time

kPluginShortPaths = ['/music', '/photos', '/video', '/applications']
kPluginPaths =  kPluginShortPaths + map(lambda x: x+'/', kPluginShortPaths)
kErrorBody = '<html><head><title>Not Found</title></head><body><h1>404 Not Found</h1></body></html>'
kForbiddenBody = '<html><head><title>Forbidden</title></head><body><h1>403 Forbidden</h1></body></html>'

die = False

# TODO: Track library section for ratingKey so libraries can be white/black-listed later
# TODO: Examples of how to whitelist certain devices
# TODO: Catch and pass on error codes
# TODO: Block */:/transcode requests to identifiers matching hidden plug-ins.
# TODO: Have this work with other HTTP verbs: HEAD, PUT, TRACE, OPTIONS, CONNECT, PATCH

def getURL(url, data=None, headers=None):
  # print 'Requesting', url, data, headers
  headerDict = dict()
  if headers:
    for k, v in headers:
      headerDict[k] = v
    
  if not data: data = None
  req = urllib2.Request(url, data, headerDict)
  f = urllib2.urlopen(req)
  content = f.read()
  
  headerStr = str(f.headers)
  headers = dict()
  for headerLine in headerStr.split('\r\n')[:-1]:
    k, v = headerLine.split(':', 1)
    headers[k] = v[1:]
  return content, headers

def getEtree(url, data=None, headers=None):
  content, headers = getURL(url, data, headers)
  return etree.fromstring(content), headers

def getJSON(url, data=None, headers=None):
  content, headers = getURL(url, data, headers)
  return json.load(content), headers

def _bare_address_string(self):
  # Thank you, thank you, thank you, Santoso Wijaya (santa4nt) http://bugs.python.org/issue6085
  host, port = self.client_address[:2]
  return '%s' % host


def validateMetadataKey(key):
  global _metadataKeys, _libCacheTimes
  try: return _metadataKeys[key][0]
  except KeyError: pass
  print 'Getting metadata keys'
  for lib in getEtree('http://127.0.0.1:32400/library/sections/')[0].xpath('/MediaContainer/Directory'):
    libKey = lib.get('key')
    updatedAt = lib.get('updatedAt')
    if libKey not in _libCacheTimes or _libCacheTimes[libKey] != updatedAt:
      _libCacheTimes[libKey] = updatedAt
      v = libKey not in libBlacklist
      _metadataKeys.update(getMetadataKeys('http://127.0.0.1:32400/library/sections/%s/all' % libKey, v))
    print 'Finished loading ', lib.get('title')
  _metadataKeysCacheTime = datetime.datetime.now()
  with open('cache', 'w') as f:
    pickle.dump({'metadataKeys': _metadataKeys, 'libCacheTimes': _libCacheTimes}, f)
  print 'Saved metadata info'
  return _metadataKeys[key]

def getMetadataKeys(path, v):
  metadataKeys = dict()
  for item in getEtree(path)[0].xpath('/MediaContainer/*'):
    key = item.get('ratingKey')
    try: lastUpdate = metadataKeys[key][0]
    except KeyError: lastUpdate = 0 
    updatedAt = item.get('updatedAt')
    metadataKeys[key] = (v, updatedAt)
    
    if item.tag == 'Directory' and updatedAt != lastUpdate:
      for subItem in getEtree('http://127.0.0.1:32400/library/metadata/' + key + '/children')[0].xpath('/MediaContainer/*'):
        try: metadataKeys[subItem.get('ratingKey')] = v
        except: pass
      for subItem in getEtree('http://127.0.0.1:32400/library/metadata/' + key + '/allLeaves')[0].xpath('/MediaContainer/*'):
        metadataKeys[subItem.get('ratingKey')] = v
  return metadataKeys

_nonPlexOnlinePlugins = list()
_nonPlexOnlinePluginsCacheTime = datetime.datetime(datetime.MINYEAR, 1, 1)
def getNonPlexOnlinePlugins():
  global _nonPlexOnlinePlugins, _nonPlexOnlinePluginsCacheTime
  elapsed = datetime.datetime.now() - _nonPlexOnlinePluginsCacheTime
  if elapsed.total_seconds() < 3600: return _nonPlexOnlinePlugins
  print 'Getting online plug-ins'
  identifiers = list()
  for item in json.load(urllib.urlopen('http://plugins.plexapp.com/apps/all.json')):
    identifiers.append(item['app']['identifier'])
  plugins = list()
  for item in etree.parse('http://127.0.0.1:32400/system/plugins/all').xpath('/MediaContainer/Directory'):
    if item.get('identifier') not in identifiers: plugins.append(base64.b64decode(item.get('key') + '==').split('/')[-1])
  _nonPlexOnlinePlugins = plugins
  _nonPlexOnlinePluginsCacheTime = datetime.datetime.now()
  return plugins
  
class PMSHandler(BaseHTTPRequestHandler):
  def getDataAndHeaders(self):
    headers = self.headers.items()
    if 'Content-Length' in headers:
      varLen = int(headers['Content-Length'])
      data = s.rfile.read(varLen)
    else: data = None
    return data, headers

  def stripSections(self, path, itemType):
    out = ''
    itemCount = 0
    
    if itemType == 'lib': shouldStrip = lambda item:item.get('key') in libBlacklist
    elif itemType == 'libMenu': shouldStrip = lambda item: viewerAge and contentRatings.minAgeForContentRating(item.get('contentRating')) > viewerAge
    elif itemType == 'libSystem': shouldStrip = lambda item:base64.b64decode(item.get('key') + '==').split('/')[-1] in libBlacklist
    elif itemType == 'plugin': shouldStrip = lambda item:item.get('key') in pluginBlacklist
    elif itemType == 'pluginSystem': shouldStrip = lambda item:base64.b64decode(item.get('key') + '==').split('/')[-1] in pluginBlacklist
    elif itemType == 'pluginOnlineOnly':
      combinedBlacklist = getNonPlexOnlinePlugins() + pluginBlacklist
      shouldStrip = lambda item:item.get('key') in combinedBlacklist
    elif itemType == 'pluginSystemOnlineOnly':
      combinedBlacklist = getNonPlexOnlinePlugins() + pluginBlacklist
      shouldStrip = lambda item: base64.b64decode(item.get('key') + '==').split('/')[-1] in combinedBlacklist
    else:
      print 'unknown item type ' + itemType
      shouldStrip = lambda item:False
    
    original, headers = getEtree('http://127.0.0.1:32400' + path, *self.getDataAndHeaders())
    for item in original.xpath('/MediaContainer/*'):
      if not shouldStrip(item):
        out += etree.tostring(item)
        itemCount += 1
    
    # Populate top level element
    outer = '<?xml version="1.0" encoding="UTF-8"?>\n<MediaContainer '
    for k,v in original.xpath('/MediaContainer')[0].attrib.iteritems():
      if k != 'size': outer += '%s="%s" ' % (k, v)
    outer += 'size="%i">\n' % itemCount
    return outer + out + '</MediaContainer>', headers
  
  def getBlacklistedFolders(self):
    folderBlacklist = list()
    sections = etree.parse('http://127.0.0.1:32400/library/sections')
    for item in sections.xpath('/MediaContainer/Directory'):
      if item.get('key') in libBlacklist:
        for location in item.xpath('./Location'):
          folderBlacklist.append(location.get('path'))
    return folderBlacklist
  
  def stripFolders(self, path):
    folderBlacklist = self.getBlacklistedFolders()
    out = ''
    itemCount = 0
    content, headers = etree.parse('http://127.0.0.1:32400' + path, *self.getDataAndHeaders())
    for item in content.xpath('/MediaContainer/Path'):
      if item.get('path') not in folderBlacklist:
        out += etree.tostring(item)
        itemCount += 1
    return '<?xml version="1.0" encoding="UTF-8"?>\n<MediaContainer size="%i">\n' % itemCount + out + '</MediaContainer>', headers
  
  def handleRequest(self):
    err = forbid = passthrough = False
    
    if self.path == '/library/sections' or self.path == '/library/sections/':
      out, headers = self.stripSections(self.path, 'lib')
    elif self.path.startswith('/system/library/sections'):
      out, headers = self.stripSections(self.path, 'libSystem')
    elif self.path.startswith('/library/sections/'):
      if self.path.split('/')[3] in libBlacklist: err = True
      elif re.match(r'/library/sections/[^/]+/.+', self.path): out, headers = self.stripSections(self.path, 'libMenu')
      else: passthrough = True
    elif self.path in kPluginPaths:
      kind = 'pluginOnlineOnly' if plexOnlineOnly else 'plugin'
      out, headers = self.stripSections(self.path, kind)
    elif re.match(r'/system/plugins/[^/]+[/]?$', self.path):
      kind = 'pluginSystemOnlineOnly' if plexOnlineOnly else 'pluginSystem'
      out, headers = self.stripSections(self.path, kind)
    elif re.match(r'/[^/]+/:/transcode', self.path):
      try: ratingKey = self.path.split('ratingKey=')[1].split('&')[0]
      except IndexError:
        print 'Transcode request lacking ratingKey ', self.path
        try: url = urllib.unquote(self.path.split('url=')[1].split('&')[0])
        except IndexError: err = True
        else:
          if urlparse.urlparse(url).path in self.getBlacklistedFolders(): err = True
          else: passthrough = True
      else:
        try: contentRating = etree.parse('http://127.0.0.1:32400/library/metadata/' + ratingKey).xpath('/MediaContainer/*/@contentRating')
        except: err = True
        else:
          if contentRating and viewerAge and contentRatings.minAgeForContentRating(contentRating[0]) > viewerAge or not validateMetadataKey(ratingKey): err = True
          else: passthrough = True
    elif any(ifilter(lambda p: self.path.startswith(p), kPluginShortPaths)):
      pathComponents = self.path.split('/')
      if len(pathComponents) < 3:
        err = True
      else:
        pluginName = pathComponents[2]
        if plexOnlineOnly and pluginName in getNonPlexOnlinePlugins() or pluginName in pluginBlacklist:
          err = True
        else:
          passthrough = True
    elif self.path.startswith('/services/browse'):
      if noBrowse:
        forbid = True
      else:
        out, headers = self.stripFolders(self.path)
    elif noManage and self.path.startswith('/manage'):
      forbid = True
    elif re.match(r'/library/metadata/.+', self.path):
      try: content, headers = getEtree('http://127.0.0.1:32400' + self.path, *self.getDataAndHeaders())
      except: err = True
      else:
        contentRating = content.xpath('/MediaContainer/*/@contentRating')
        if contentRating and viewerAge and contentRatings.minAgeForContentRating(contentRating[0]) > viewerAge or not validateMetadataKey(self.path.split('/')[-1]):
          err = True
        else: out = etree.tostring(content)
    else:
      passthrough = True
    
    if passthrough:
      out, headers = getURL('http://127.0.0.1:32400' + self.path, *self.getDataAndHeaders())
    
    if err:
      self.send_response(404, 'Not found')
      headers = {'Content-Type': 'text/html'}
      out = kErrorBody
    elif forbid:
      self.send_response(403, 'Forbidden')
      headers = {'Content-Type': 'text/html'}
      out = kForbiddenBody
    else:
      self.send_response(200)
    
    for k, v in headers.iteritems():
      if k != 'Content-Length': self.send_header(k, v)
      else: self.send_header('Content-Length', len(out))
    self.end_headers()
    
    self.wfile.write(out)

  def do_GET(self):
    self.handleRequest()
  
  def do_POST(self):
    self.handleRequest()

def updater():
  global die
  while not die:
    try: validateMetadataKey(-1)
    except:pass
    lastUpdate = datetime.datetime.now()
    while not die and (datetime.datetime.now() - lastUpdate).total_seconds() < 600: pass

def main():
  global _metadataKeys, _libCacheTimes, die
  try:
    with open('cache') as f:
      savedInfo = pickle.load(f)
    _libCacheTimes = savedInfo['libCacheTimes']
    _metadataKeys = savedInfo['metadataKeys']
  except IOError:
    print 'Loading library info for the first time. This might take a while'
    _metadataKeys = dict()
    _libCacheTimes = dict()    
    try: validateMetadataKey(-1)
    except:pass
  threading.Thread(target=updater).start()
  
  BaseHTTPRequestHandler.address_string = _bare_address_string # see comment above
  print 'starting server'
  server = HTTPServer(('127.0.0.1', 32404), PMSHandler)
  print 'server started'
  if plexOnlineOnly: getNonPlexOnlinePlugins()
  try: server.serve_forever()
  except KeyboardInterrupt:
    print 'Shutting down'
    server.socket.close()
    die = True

if __name__ == '__main__':
  main()

